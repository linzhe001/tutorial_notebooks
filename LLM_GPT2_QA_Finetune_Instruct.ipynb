{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a51d6d10e52f43239282589c229392ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4323644c1e4e4b73b03b8b34beb84b65",
              "IPY_MODEL_f4d377966bcd44a49c1aac0267f2ba9e",
              "IPY_MODEL_b74555c39e234317982f4984e7366642"
            ],
            "layout": "IPY_MODEL_97d349d63ade4c8487d2261da469d025"
          }
        },
        "4323644c1e4e4b73b03b8b34beb84b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ad449fcf4d48059435785e2fc5f491",
            "placeholder": "​",
            "style": "IPY_MODEL_d03f383026c04cc997c5313aca567f3b",
            "value": "Map: 100%"
          }
        },
        "f4d377966bcd44a49c1aac0267f2ba9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dde056464294a6bbf218e05a460eedd",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e62077f263084db693072bbac6916f5b",
            "value": 5
          }
        },
        "b74555c39e234317982f4984e7366642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c1f17b9aa747aa8fd9124c261b8a67",
            "placeholder": "​",
            "style": "IPY_MODEL_73032d6b2c234302957f551a188100ea",
            "value": " 5/5 [00:00&lt;00:00, 91.29 examples/s]"
          }
        },
        "97d349d63ade4c8487d2261da469d025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ad449fcf4d48059435785e2fc5f491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03f383026c04cc997c5313aca567f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dde056464294a6bbf218e05a460eedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62077f263084db693072bbac6916f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03c1f17b9aa747aa8fd9124c261b8a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73032d6b2c234302957f551a188100ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8590044b6e094fa68b86b66b0f90ab39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b49bfbe5ea27424eb613bc574050d6fd",
              "IPY_MODEL_07d1780b9c194a5585b714e7ed80070e",
              "IPY_MODEL_5cd09d4e706f4164b12165d6d917ad42"
            ],
            "layout": "IPY_MODEL_b0ffa0f9ae334ddcb93fe2c96e8ce8e7"
          }
        },
        "b49bfbe5ea27424eb613bc574050d6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30805872bca043ca891d44813232befe",
            "placeholder": "​",
            "style": "IPY_MODEL_8bbfb1b5cd314cf2855a05a58eb3b26e",
            "value": "Map: 100%"
          }
        },
        "07d1780b9c194a5585b714e7ed80070e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d359873aea524fb0a12580521799dc5c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9cc3084212844dcb73d0ba91cdf868a",
            "value": 5
          }
        },
        "5cd09d4e706f4164b12165d6d917ad42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2ca9184bcd49bea123643e3e837137",
            "placeholder": "​",
            "style": "IPY_MODEL_480768afdf204c9a875824a1a9f1ba7e",
            "value": " 5/5 [00:00&lt;00:00, 59.23 examples/s]"
          }
        },
        "b0ffa0f9ae334ddcb93fe2c96e8ce8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30805872bca043ca891d44813232befe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbfb1b5cd314cf2855a05a58eb3b26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d359873aea524fb0a12580521799dc5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cc3084212844dcb73d0ba91cdf868a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b2ca9184bcd49bea123643e3e837137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480768afdf204c9a875824a1a9f1ba7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c58e3a1f16ed483687b87d04025324b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d54e98059136411d9ba062f4b78eb4c0",
              "IPY_MODEL_16efc5e0d4b2457284defa493f38b4af",
              "IPY_MODEL_8e9820a97577444faa191c8b35a8eb3b"
            ],
            "layout": "IPY_MODEL_8cfb1303e33b4f26b32afb0a67d8390f"
          }
        },
        "d54e98059136411d9ba062f4b78eb4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a2a2b404244bbbad3971fc19d9d0ab",
            "placeholder": "​",
            "style": "IPY_MODEL_d33dbbcc55c048b4b675d929da783da1",
            "value": "Map: 100%"
          }
        },
        "16efc5e0d4b2457284defa493f38b4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e30f29b47e240788e05ad69eb1ef134",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f112074a9554ed3abf1b662dbf390c3",
            "value": 5
          }
        },
        "8e9820a97577444faa191c8b35a8eb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ee93bbaaf6442295e3ed30b26f233c",
            "placeholder": "​",
            "style": "IPY_MODEL_e3039023e78f4e12b98f6d98b8436314",
            "value": " 5/5 [00:00&lt;00:00, 96.69 examples/s]"
          }
        },
        "8cfb1303e33b4f26b32afb0a67d8390f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a2a2b404244bbbad3971fc19d9d0ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33dbbcc55c048b4b675d929da783da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e30f29b47e240788e05ad69eb1ef134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f112074a9554ed3abf1b662dbf390c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4ee93bbaaf6442295e3ed30b26f233c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3039023e78f4e12b98f6d98b8436314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a73317bb2fd4875b0f3ad15f4f02dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_658405d7ceff46a9825920ac1dc28dfb",
              "IPY_MODEL_d0d1f53873f94a2bb943003a84893884",
              "IPY_MODEL_8948f95d09244457a493b553113465b3"
            ],
            "layout": "IPY_MODEL_7fe8662834144115b25e8a6d14a23171"
          }
        },
        "658405d7ceff46a9825920ac1dc28dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158c07b4f89a495e8e550613ebc1357c",
            "placeholder": "​",
            "style": "IPY_MODEL_c084c7c7e13444049755d65d5bcd7210",
            "value": "Map: 100%"
          }
        },
        "d0d1f53873f94a2bb943003a84893884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca594a82a1b544268b62e486d2ec9fc9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_596e03a4c9d440ba89e79e1117b5e2b5",
            "value": 5
          }
        },
        "8948f95d09244457a493b553113465b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e621d7be9a504633ab752e82d8d03ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_b63897def53440548f67f623a35f5ef7",
            "value": " 5/5 [00:00&lt;00:00, 94.01 examples/s]"
          }
        },
        "7fe8662834144115b25e8a6d14a23171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158c07b4f89a495e8e550613ebc1357c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c084c7c7e13444049755d65d5bcd7210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca594a82a1b544268b62e486d2ec9fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596e03a4c9d440ba89e79e1117b5e2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e621d7be9a504633ab752e82d8d03ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63897def53440548f67f623a35f5ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linzhe001/tutorial_notebooks/blob/main/LLM_GPT2_QA_Finetune_Instruct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtglDM63X5tN",
        "outputId": "dff3b699-59f3-420f-dd37-5ebf6aa1d51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m471.0/480.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcYt80sfinYT",
        "outputId": "4ce57336-5535-4ffd-a4cf-b960daa57357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.47.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zeros-shot prediction"
      ],
      "metadata": {
        "id": "-Q5XeUiZmuTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "# Add padding token if necessary\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Inference function\n",
        "def generate_answer(question):\n",
        "    model.eval()\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=50, pad_token_id=tokenizer.pad_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "# Example inference\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question)\n",
        "print(f\"Q: {question}\\nA: {answer}\")"
      ],
      "metadata": {
        "id": "TlJoougDHC2P",
        "outputId": "6bef3fdc-e538-4097-c748-6c20f7afc580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the capital of France?\n",
            "A: The capital of France\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning - Instruct<br>\n",
        "target_text = f\"{example['answer']} {tokenizer.eos_token}\""
      ],
      "metadata": {
        "id": "3hIkW1CEt1Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Add padding token if necessary\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Prepare 5 QA samples for instruction tuning\n",
        "train_qa_samples = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "    {\"question\": \"What is the largest planet?\", \"answer\": \"The largest planet is Jupiter.\"},\n",
        "    {\"question\": \"Who painted the Mona Lisa?\", \"answer\": \"Leonardo da Vinci painted the Mona Lisa.\"},\n",
        "    {\"question\": \"What is the speed of light?\", \"answer\": \"The speed of light is approximately 299,792 kilometers per second.\"}\n",
        "]\n",
        "\n",
        "valid_qa_samples = [\n",
        "    {\"question\": \"Which city is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Can you tell me who authored '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "    {\"question\": \"What planet is the biggest in our solar system?\", \"answer\": \"The largest planet is Jupiter.\"},\n",
        "    {\"question\": \"Who is the artist behind the Mona Lisa?\", \"answer\": \"Leonardo da Vinci painted the Mona Lisa.\"},\n",
        "    {\"question\": \"How fast does light travel?\", \"answer\": \"The speed of light is approximately 299,792 kilometers per second.\"}\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']} Answer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "\n",
        "\n",
        "    # Tokenize inputs and labels\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=256)\n",
        "    labels = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "    # Set labels to ignore padding tokens\n",
        "    inputs[\"labels\"] = [label if label != tokenizer.pad_token_id else -100 for label in labels[\"input_ids\"]]\n",
        "    return inputs\n",
        "\n",
        "# Convert samples to Hugging Face dataset and preprocess\n",
        "dataset_train = Dataset.from_list(train_qa_samples)\n",
        "tokenized_dataset_train = dataset_train.map(preprocess_data)\n",
        "\n",
        "dataset_valid = Dataset.from_list(valid_qa_samples)\n",
        "tokenized_dataset_valid = dataset_valid.map(preprocess_data)\n",
        "\n",
        "# Calculate save_steps based on dataset size and batch size\n",
        "batch_size = 5  # Define the batch size used for training\n",
        "num_train_samples = len(tokenized_dataset_train)\n",
        "save_steps = num_train_samples // batch_size  # Number of steps per epoch\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-qa-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save checkpoints based on number of steps\n",
        "    save_steps=save_steps,  # Save model at the end of every epoch\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    logging_steps=1,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    num_train_epochs=30,\n",
        "    save_total_limit=10,\n",
        "    push_to_hub=False,\n",
        "    report_to=[],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    save_safetensors=False,\n",
        ")\n",
        "\n",
        "\n",
        "# Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset_train,\n",
        "    eval_dataset=tokenized_dataset_valid,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "# model.save_pretrained(\"./gpt2-qa-finetuned\")\n",
        "trainer.save_model(\"./gpt2-qa-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-qa-finetuned\")\n",
        "\n",
        "# Load the fine-tuned model for inference\n",
        "model_name = \"./gpt2-qa-finetuned\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Inference function\n",
        "def generate_answer(question):\n",
        "    model.eval()\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=50, pad_token_id=tokenizer.pad_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "# Example inference\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question)\n",
        "print(f\"Q: {question}\\nA: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a51d6d10e52f43239282589c229392ee",
            "4323644c1e4e4b73b03b8b34beb84b65",
            "f4d377966bcd44a49c1aac0267f2ba9e",
            "b74555c39e234317982f4984e7366642",
            "97d349d63ade4c8487d2261da469d025",
            "57ad449fcf4d48059435785e2fc5f491",
            "d03f383026c04cc997c5313aca567f3b",
            "3dde056464294a6bbf218e05a460eedd",
            "e62077f263084db693072bbac6916f5b",
            "03c1f17b9aa747aa8fd9124c261b8a67",
            "73032d6b2c234302957f551a188100ea",
            "8590044b6e094fa68b86b66b0f90ab39",
            "b49bfbe5ea27424eb613bc574050d6fd",
            "07d1780b9c194a5585b714e7ed80070e",
            "5cd09d4e706f4164b12165d6d917ad42",
            "b0ffa0f9ae334ddcb93fe2c96e8ce8e7",
            "30805872bca043ca891d44813232befe",
            "8bbfb1b5cd314cf2855a05a58eb3b26e",
            "d359873aea524fb0a12580521799dc5c",
            "b9cc3084212844dcb73d0ba91cdf868a",
            "5b2ca9184bcd49bea123643e3e837137",
            "480768afdf204c9a875824a1a9f1ba7e"
          ]
        },
        "id": "_kqPDbJgtaH-",
        "outputId": "000a580a-73cd-42e3-a2a3-2d8042611f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a51d6d10e52f43239282589c229392ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8590044b6e094fa68b86b66b0f90ab39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-43-89e1ce3bd04b>:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 12:08, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>11.019800</td>\n",
              "      <td>11.029708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>10.843100</td>\n",
              "      <td>11.029708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>10.374700</td>\n",
              "      <td>11.029708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>10.995600</td>\n",
              "      <td>11.029708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>10.864800</td>\n",
              "      <td>9.971808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>9.661200</td>\n",
              "      <td>9.971808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>9.606000</td>\n",
              "      <td>9.302272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>8.682900</td>\n",
              "      <td>8.801450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>8.158200</td>\n",
              "      <td>8.394403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>7.584000</td>\n",
              "      <td>8.043612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>6.930300</td>\n",
              "      <td>7.722245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>6.531800</td>\n",
              "      <td>7.412417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>5.777100</td>\n",
              "      <td>7.130551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>5.459200</td>\n",
              "      <td>6.852025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4.963000</td>\n",
              "      <td>6.596217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4.954400</td>\n",
              "      <td>6.378778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>4.217700</td>\n",
              "      <td>6.161884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>3.701800</td>\n",
              "      <td>6.072902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>3.788100</td>\n",
              "      <td>5.963122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.741400</td>\n",
              "      <td>5.861511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.754300</td>\n",
              "      <td>5.786817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.620900</td>\n",
              "      <td>5.835902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>2.500900</td>\n",
              "      <td>6.091701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3.018500</td>\n",
              "      <td>6.313904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.222700</td>\n",
              "      <td>6.288984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.995700</td>\n",
              "      <td>6.200451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>2.004600</td>\n",
              "      <td>6.088067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.176200</td>\n",
              "      <td>5.976971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.108200</td>\n",
              "      <td>5.857450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.731700</td>\n",
              "      <td>5.712957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the capital of France?\n",
            "A: Paris. capital. of. France. per cent. of. per cent. of. per cent. of. per cent. of. per cent. of. per cent. of. per cent. of. per cent. of. per cent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "model_name = \"/content/gpt2-qa-finetuned/checkpoint-30\"\n",
        "\n",
        "# Load the fine-tuned model for inference\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Inference function\n",
        "def generate_answer(question):\n",
        "    model.eval()\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=10, pad_token_id=tokenizer.pad_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "# Example inference\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question)\n",
        "print(f\"Q: {question}\\nA: {answer}\")"
      ],
      "metadata": {
        "id": "ikvOFGYWACCd",
        "outputId": "970a3b62-91c8-4323-ef88-56211da4c675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the capital of France?\n",
            "A: Paris. capital. of. France. per cent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning - Instruct with train-valid scratch"
      ],
      "metadata": {
        "id": "RVgXNBisJU2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
        "from datasets import Dataset\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Seed setting function\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 50\n",
        "set_seed(seed)\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Add padding token if necessary\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Prepare 5 QA samples for training and validation\n",
        "train_qa_samples = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "    {\"question\": \"What is the largest planet?\", \"answer\": \"The largest planet is Jupiter.\"},\n",
        "    {\"question\": \"Who painted the Mona Lisa?\", \"answer\": \"Leonardo da Vinci painted the Mona Lisa.\"},\n",
        "    {\"question\": \"What is the speed of light?\", \"answer\": \"The speed of light is approximately 299,792 kilometers per second.\"}\n",
        "]\n",
        "\n",
        "valid_qa_samples = [\n",
        "    {\"question\": \"Which city is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Can you tell me who authored '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "    {\"question\": \"What planet is the biggest in our solar system?\", \"answer\": \"The largest planet is Jupiter.\"},\n",
        "    {\"question\": \"Who is the artist behind the Mona Lisa?\", \"answer\": \"Leonardo da Vinci painted the Mona Lisa.\"},\n",
        "    {\"question\": \"How fast does light travel?\", \"answer\": \"The speed of light is approximately 299,792 kilometers per second.\"}\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']} Answer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "\n",
        "    # Tokenize inputs and labels\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=256)\n",
        "    labels = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "    # Set labels to ignore padding tokens\n",
        "    inputs[\"labels\"] = [label if label != tokenizer.pad_token_id else -100 for label in labels[\"input_ids\"]]\n",
        "    return inputs\n",
        "\n",
        "# Convert samples to dataset and preprocess\n",
        "dataset_train = Dataset.from_list(train_qa_samples).map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "dataset_valid = Dataset.from_list(valid_qa_samples).map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Convert to PyTorch DataLoader\n",
        "batch_size = 2\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.tensor([item[\"input_ids\"] for item in batch])\n",
        "    attention_mask = torch.tensor([item[\"attention_mask\"] for item in batch])\n",
        "    labels = torch.tensor([item[\"labels\"] for item in batch])\n",
        "    return input_ids, attention_mask, labels\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Cross-entropy loss function ignoring padding tokens\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "# Function to save the best model based on validation loss\n",
        "def save_best_model(model, tokenizer, epoch, best_loss, current_loss, save_path=\"./gpt2-qa-best-loss\"):\n",
        "    if current_loss < best_loss:\n",
        "        best_loss = current_loss\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        model.save_pretrained(save_path)\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Best model saved at epoch {epoch} with validation loss: {best_loss:.4f}\")\n",
        "    return best_loss\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, num_epochs=10):\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Shift labels and logits for proper alignment\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "            # Flatten logits and labels for loss calculation\n",
        "            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
        "            shift_labels = shift_labels.view(-1)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(shift_logits, shift_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = validate(model, valid_loader, criterion)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Save best model based on validation loss\n",
        "        best_val_loss = save_best_model(model, tokenizer, epoch + 1, best_val_loss, avg_val_loss)\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Shift labels and logits for proper alignment\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "            # Flatten logits and labels for loss calculation\n",
        "            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
        "            shift_labels = shift_labels.view(-1)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(shift_logits, shift_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Start training\n",
        "train(model, train_loader, valid_loader, optimizer, criterion, num_epochs=10)\n",
        "\n",
        "# Load the best fine-tuned model for inference\n",
        "model_name = \"./gpt2-qa-best-loss\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Inference function\n",
        "def generate_answer(question):\n",
        "    model.eval()\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=50, pad_token_id=tokenizer.pad_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "# Example inference\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question)\n",
        "print(f\"Q: {question}\\nA: {answer}\")\n"
      ],
      "metadata": {
        "id": "XKVaatDFlK-a",
        "outputId": "751962b7-5027-465f-f3d3-ff5dde31e882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512,
          "referenced_widgets": [
            "c58e3a1f16ed483687b87d04025324b7",
            "d54e98059136411d9ba062f4b78eb4c0",
            "16efc5e0d4b2457284defa493f38b4af",
            "8e9820a97577444faa191c8b35a8eb3b",
            "8cfb1303e33b4f26b32afb0a67d8390f",
            "f6a2a2b404244bbbad3971fc19d9d0ab",
            "d33dbbcc55c048b4b675d929da783da1",
            "5e30f29b47e240788e05ad69eb1ef134",
            "4f112074a9554ed3abf1b662dbf390c3",
            "e4ee93bbaaf6442295e3ed30b26f233c",
            "e3039023e78f4e12b98f6d98b8436314",
            "0a73317bb2fd4875b0f3ad15f4f02dff",
            "658405d7ceff46a9825920ac1dc28dfb",
            "d0d1f53873f94a2bb943003a84893884",
            "8948f95d09244457a493b553113465b3",
            "7fe8662834144115b25e8a6d14a23171",
            "158c07b4f89a495e8e550613ebc1357c",
            "c084c7c7e13444049755d65d5bcd7210",
            "ca594a82a1b544268b62e486d2ec9fc9",
            "596e03a4c9d440ba89e79e1117b5e2b5",
            "e621d7be9a504633ab752e82d8d03ec7",
            "b63897def53440548f67f623a35f5ef7"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c58e3a1f16ed483687b87d04025324b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a73317bb2fd4875b0f3ad15f4f02dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 10.1111, Validation Loss: 9.2618\n",
            "Best model saved at epoch 1 with validation loss: 9.2618\n",
            "Epoch 2/10, Training Loss: 8.3192, Validation Loss: 8.3590\n",
            "Best model saved at epoch 2 with validation loss: 8.3590\n",
            "Epoch 3/10, Training Loss: 6.9464, Validation Loss: 7.6235\n",
            "Best model saved at epoch 3 with validation loss: 7.6235\n",
            "Epoch 4/10, Training Loss: 6.2921, Validation Loss: 6.9456\n",
            "Best model saved at epoch 4 with validation loss: 6.9456\n",
            "Epoch 5/10, Training Loss: 5.3403, Validation Loss: 6.3800\n",
            "Best model saved at epoch 5 with validation loss: 6.3800\n",
            "Epoch 6/10, Training Loss: 4.7640, Validation Loss: 5.9190\n",
            "Best model saved at epoch 6 with validation loss: 5.9190\n",
            "Epoch 7/10, Training Loss: 3.3056, Validation Loss: 5.6187\n",
            "Best model saved at epoch 7 with validation loss: 5.6187\n",
            "Epoch 8/10, Training Loss: 2.7980, Validation Loss: 5.7395\n",
            "Epoch 9/10, Training Loss: 2.8324, Validation Loss: 5.1642\n",
            "Best model saved at epoch 9 with validation loss: 5.1642\n",
            "Epoch 10/10, Training Loss: 2.2080, Validation Loss: 4.7278\n",
            "Best model saved at epoch 10 with validation loss: 4.7278\n",
            "Q: What is the capital of France?\n",
            "A: Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference: Greedy Search"
      ],
      "metadata": {
        "id": "GDblYXZv0RPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def greedy_generate_answer(question, max_length=50):\n",
        "    \"\"\"\n",
        "    Generate an answer using greedy search.\n",
        "\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "\n",
        "    # Prepare input with the instruction-based format\n",
        "    input_text = f\"Question: {question} Answer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Initialize generated token IDs with input\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            # Get the model's output logits\n",
        "            outputs = model(input_ids=generated_ids)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Select the token with the highest probability (greedy search)\n",
        "            next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "\n",
        "            # Append the new token to the sequence\n",
        "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
        "\n",
        "            # Stop generating if the EOS token is reached\n",
        "            if next_token_id.item() == tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "    # Decode the generated token IDs to text\n",
        "    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "# model_name = \"./gpt2-qa-finetuned\"  # Change to your model path\n",
        "# model_name = \"./gpt2-qa-best\"\n",
        "model_name = \"./gpt2-qa-best-loss\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ensure padding token is set\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example usage\n",
        "question = \"What is the capital of France?\"\n",
        "answer = greedy_generate_answer(question)\n",
        "print(f\"Q: {question}\\nA: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL52-SSFwxvk",
        "outputId": "615b9761-44f4-4f52-acc9-5c72fa417f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the capital of France?\n",
            "A: Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference: Beam Search"
      ],
      "metadata": {
        "id": "vp6T8-Tm0d-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "def generate_answer(question, model, tokenizer, max_length=50, num_beams=5, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate an answer using beam search for the fine-tuned GPT-2 model.\n",
        "\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        model (GPT2LMHeadModel): The fine-tuned model.\n",
        "        tokenizer (GPT2Tokenizer): The tokenizer.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "        num_beams (int): Number of beams for beam search.\n",
        "        device (str): The device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare input text\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # Extract input_ids and attention_mask\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Initialize beams\n",
        "    beams = [(input_ids, attention_mask, 0.0)]  # List of (sequence, attention_mask, score)\n",
        "    completed_sequences = []\n",
        "\n",
        "    # Beam search loop\n",
        "    for _ in range(max_length):\n",
        "        new_beams = []\n",
        "\n",
        "        for seq, mask, score in beams:\n",
        "            # Stop expanding if sequence ends with EOS token\n",
        "            if seq[0, -1] == tokenizer.eos_token_id:\n",
        "                completed_sequences.append((seq, score))  # Append sequence and score\n",
        "                continue\n",
        "\n",
        "            # Forward pass\n",
        "            with torch.no_grad():\n",
        "                outputs = model(seq, attention_mask=mask)\n",
        "                logits = outputs.logits[:, -1, :]  # Logits of the last token\n",
        "                probs = F.log_softmax(logits, dim=-1)  # Convert to log probabilities\n",
        "\n",
        "            # Get top-k tokens and their log probabilities\n",
        "            top_k_probs, top_k_tokens = torch.topk(probs, num_beams, dim=-1)\n",
        "\n",
        "            # Expand each beam\n",
        "            for prob, token in zip(top_k_probs[0], top_k_tokens[0]):\n",
        "                new_seq = torch.cat([seq, token.unsqueeze(0).unsqueeze(0)], dim=1)  # Append token\n",
        "                new_mask = torch.cat([mask, torch.ones((1, 1), device=device)], dim=1)  # Update attention mask\n",
        "                new_score = score + prob.item()  # Accumulate log probability as float\n",
        "                new_beams.append((new_seq, new_mask, new_score))\n",
        "\n",
        "        # Sort new beams by score and keep top-k\n",
        "        new_beams = sorted(new_beams, key=lambda x: x[2], reverse=True)[:num_beams]\n",
        "        beams = new_beams\n",
        "\n",
        "        # Break if all beams end with EOS token\n",
        "        if all(seq[0, -1] == tokenizer.eos_token_id for seq, _, _ in beams):\n",
        "            break\n",
        "\n",
        "    # Add remaining beams to completed sequences\n",
        "    completed_sequences.extend([(seq, float(score)) for seq, _, score in beams])\n",
        "\n",
        "    # Select the sequence with the highest score\n",
        "    best_sequence, _ = max(completed_sequences, key=lambda x: x[1])\n",
        "\n",
        "    # Decode the tokens to text\n",
        "    answer = tokenizer.decode(best_sequence[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-qa-finetuned\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-qa-finetuned\")\n",
        "\n",
        "# Test the generate_answer function\n",
        "question = \"What is the capital of France?\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "st = time.time()\n",
        "answer = generate_answer(question, model, tokenizer, max_length=50, num_beams=5, device=device)\n",
        "en = time.time()\n",
        "print('total time:', en-st)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "WRxYr86AyV_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f67a683-47c0-4602-80e2-60199f774d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total time: 4.90141487121582\n",
            "Question: What is the capital of France?\n",
            "Answer:. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris. Paris\n"
          ]
        }
      ]
    }
  ]
}